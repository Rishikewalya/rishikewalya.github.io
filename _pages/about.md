---
permalink: /
#layout: archive
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<div hidden="hidden">
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=P0DmcjPhTVQDSVsO6eLpfLlblpD7aYEdFi8dEehI1TI&cl=ffffff&w=a"></script>
</div>

<span class="small_font">I am a <b>Data Engineer at ICICI Bank</b> in the Data & Intelligence Platform division. I completed my Bachelor of Engineering in Computer Engineering from the <b>University of Mumbai</b> (GPA: 8.06/10). I am grateful to have worked with researchers including Prof. <a target="_blank" href="#">Sanjay Kumar Singh</a> at IIT Varanasi and Prof. <a target="_blank" href="#">Darakhshan Khan</a> at the University of Mumbai.
<br>&emsp;&emsp;&emsp;<b>Prior Experience.</b> I was a <b>Research Intern at IIT Varanasi</b> under Prof. Sanjay Kumar Singh, working on a Uni-Sign Language Model for Machine Translation. I also conducted research at the University of Mumbai on multimodal AI for cardiac risk prediction â€” my final year thesis, CardioCare. My work on distributed training reduced training time by 48.9% and my multimodal cardiac assistant outperformed GPT-3.5 by 15% on clinical benchmarks.
<br>&emsp;&emsp;&emsp;<b>Recognition.</b> I received the <b>Best Paper Award at IEEE IATMSI 2025</b> for my work on Diabetic Retinopathy, was a 2nd Runner-Up at Techno Kagaz 2024, and secured 3rd Position at ResCon 2024 at IIT Bombay among 100+ participants.

<h3>Research Interest</h3>

<span class="small_font">
What drives my research is the idea of building AI systems that move beyond theoretical performance and create measurable impact in real-world domains such as healthcare. I am particularly interested in designing intelligent systems that are not only accurate, but scalable, interpretable, and deployable in production environments.
<br>&emsp;&emsp;&emsp;In healthcare AI, this means developing multimodal models that can combine signals like ECG data and medical text to assist in risk prediction.
<br>&emsp;&emsp;&emsp;My approach focuses on (1) building robust model architectures grounded in strong experimental validation, and (2) optimizing distributed training and data engineering pipelines to ensure these systems scale effectively. Ultimately, I aim to bridge research and production by creating AI solutions that are both technically rigorous and practically impactful.
</span>

<div class="recent_updates">Selected Research</div>
<span style="font-size:14px;margin-bottom: -25px;display: block;">*Equal Authors / <span class="highlight">Highlighted Papers</span></span>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/diabetic_retinopathy.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Attention-Enhanced Prototypical Networks for Few-Shot Microaneurysm Detection in Diabetic Retinopathy Images</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b> <i><br><b>IEEE, May 2025</b></i><a target="_blank" class="tab_paper" href="#">paper</a></div>
		<div class="win"><img src="images/trophy-icon.webp" width="10px">Best Paper Award at <a class="prize" href="#">IEEE IATMSI 2025</a></div>
		<span class="research-text">
		Proposed attention-enhanced prototypical networks for few-shot detection of microaneurysms in diabetic retinopathy images, enabling effective diagnosis under limited labeled data conditions. This work was recognized with the Best Paper Award at IEEE IATMSI 2025.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/sign_language_llm.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Enhancing Sign Language Interpretation with Multiheaded CNN, Hand Landmarks and Large Language Model (LLM)</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b> <i><br><b>IEEE, Nov 2024</b></i><a target="_blank" class="tab_paper" href="#">paper</a></div>
		<span class="research-text">
		Proposed a hybrid architecture combining multiheaded CNNs, hand landmark detection, and LLMs to enhance sign language interpretation accuracy and contextual understanding. The system improves robustness over single-model approaches by fusing spatial and semantic signals.
		</span>
	</div>
</div>
