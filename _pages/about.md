---
permalink: /
#layout: archive
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<div hidden="hidden">
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=P0DmcjPhTVQDSVsO6eLpfLlblpD7aYEdFi8dEehI1TI&cl=ffffff&w=a"></script>
</div>

<span class="small_font">I am a <b>Data Engineer at ICICI Bank</b> in the Data & Intelligence Platform division. I completed my Bachelor of Engineering in Computer Engineering from the <b>University of Mumbai</b> (GPA: 8.06/10). I am grateful to have worked with researchers including Prof. <a target="_blank" href="#">Sanjay Kumar Singh</a> at IIT Varanasi and Prof. <a target="_blank" href="#">Darakhshan Khan</a> at the University of Mumbai.
<br>&emsp;&emsp;&emsp;<b>Prior Experience.</b> I was a <b>Research Intern at IIT Varanasi</b> under Prof. Sanjay Kumar Singh, working on a Uni-Sign Language Model for Machine Translation. I also conducted research at the University of Mumbai on multimodal AI for cardiac risk prediction — my final year thesis, CardioCare. My work on distributed training reduced training time by 48.9% and my multimodal cardiac assistant outperformed GPT-3.5 by 15% on clinical benchmarks.
<br>&emsp;&emsp;&emsp;<b>Recognition.</b> I received the <b>Best Paper Award at IEEE IATMSI 2025</b> for my work on Diabetic Retinopathy, was a 2nd Runner-Up at Techno Kagaz 2024, and secured 3rd Position at ResCon 2024 at IIT Bombay among 100+ participants.

<h3>Research Interest</h3>

<span class="small_font">
What drives my research is the idea of building AI systems that move beyond theoretical performance and create measurable impact in real-world domains such as healthcare. I am particularly interested in designing intelligent systems that are not only accurate, but scalable, interpretable, and deployable in production environments.
<br>&emsp;&emsp;&emsp;In healthcare AI, this means developing multimodal models that can combine signals like ECG data and medical text to assist in risk prediction.
<br>&emsp;&emsp;&emsp;My approach focuses on (1) building robust model architectures grounded in strong experimental validation, and (2) optimizing distributed training and data engineering pipelines to ensure these systems scale effectively. Ultimately, I aim to bridge research and production by creating AI solutions that are both technically rigorous and practically impactful.
</span>

<div class="recent_updates">Selected Research</div>
<span style="font-size:14px;margin-bottom: -25px;display: block;">*Equal Authors / <span class="highlight">Highlighted Papers</span></span>

<div class="research-block highlight">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/cardiocare.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">CardioCare: Multimodal AI for Cardiac Risk Prediction</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b>, University of Mumbai | Prof. Darakhshan Khan <i><br><b>Final Year Thesis, 2024–2025</b></i></div>
		<span class="research-text">
		Built a multimodal cardiac diagnosis assistant using Retrieval-Augmented Generation (RAG) on patient records for information retrieval, combined with ECG signals and medical text. Achieved 76.8% Exact Match and 0.83 F1, outperforming GPT-3.5 by 15% on clinical benchmarks. Fine-tuned an LSTM arrhythmia classifier (48 MIT-BIH classes) with chain-of-thought prompting, reaching 0.875 AUC.
		</span>
	</div>
</div>

<div class="research-block highlight">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/unisign.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Uni-Sign Language Model for Machine Translation</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b>, IIT Varanasi | Prof. Sanjay Kumar Singh <i><br><b>Research Internship, Jan–Jun 2025</b></i></div>
		<span class="research-text">
		Reproduced and extended the Uni-Sign research architecture on the Chinese Sign Language News dataset (436+ video sequences), achieving &lt;2% deviation from published benchmark accuracy. Executed mixed-precision, multi-GPU distributed training (NVIDIA V100, PyTorch AMP), reducing training time by 48.9% and lowering inference latency by 27.3%. Designed and conducted 15+ controlled experiments, improving F1-score by 6.97% over baseline.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/diabetic_retinopathy.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Attention-Enhanced Prototypical Networks for Few-Shot Microaneurysm Detection in Diabetic Retinopathy Images</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b> <i><br><b>IEEE, May 2025</b></i><a target="_blank" class="tab_paper" href="#">paper</a></div>
		<div class="win"><img src="images/trophy-icon.webp" width="10px">Best Paper Award at <a class="prize" href="#">IEEE IATMSI 2025</a></div>
		<span class="research-text">
		Proposed attention-enhanced prototypical networks for few-shot detection of microaneurysms in diabetic retinopathy images, enabling effective diagnosis under limited labeled data conditions. This work was recognized with the Best Paper Award at IEEE IATMSI 2025.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/sign_language_llm.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Enhancing Sign Language Interpretation with Multiheaded CNN, Hand Landmarks and Large Language Model (LLM)</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b> <i><br><b>IEEE, Nov 2024</b></i><a target="_blank" class="tab_paper" href="#">paper</a></div>
		<span class="research-text">
		Proposed a hybrid architecture combining multiheaded CNNs, hand landmark detection, and LLMs to enhance sign language interpretation accuracy and contextual understanding. The system improves robustness over single-model approaches by fusing spatial and semantic signals.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/motionscript.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">MotionScript: Sign Language to Voice Converter</div>
		<div class="sub-title"><b style="color:#a115a0">Rishi Kewalya</b> <i><br><b>Academic Project</b></i></div>
		<span class="research-text">
		Designed and benchmarked 4 CNN-based architectures (including fine-tuned VGG16) on a custom dataset of 36,000+ segmented sign images (A–Z, 0–9; 1,015+ samples/class), achieving 99.63% test accuracy. Integrated a pretrained T5-Flan LLM for semantic sequence refinement and deployed a real-time inference pipeline with speech synthesis (gTTS) for live sign-to-voice conversion.
		</span>
	</div>
</div>